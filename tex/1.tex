\chapter{绪论}
语音是人类交流最常用、最直接、最有效的信息载体之一。在信息数字化时代，科学家们致力于将这种最有效的交流方式
应用于人机交互中，使得人类可以直接通过语音来与不同的机器设备交互，即语音人机交互。随着人工智能时代的到来，
简单的人机交互已经不能满足人们的需要，智能化，个性化已经成为语音人机交互的发展方向。对于机器而言，一个人机
交互的完整流程通常包括语音识别、语义理解、对话管理和语音合成四个步骤。其中语音合成作为交互的最后一个环节，
主要负责将机器生成的文本转换成语音反馈给用户。其中，所生成语音的个性化程度是影响人机交互体验的重要因素。
语音转换即可以通过对语音中的说话人特性进行调整和修改，用相对较少的数据实现对语音的个性化生成。

在深度学习的影响下，语音转换技术也得到了飞速的发展，并在个性化语音合成、发音协助、语音增强、多媒体娱乐等有着广泛的应用前景。
语音转换任务根据数据条件的不同可以分为平行语料的语音转换和非平行语料的语音转换。其中，非平行语料的语音转换由于其更符合
实际应用场景而在近年受到了越来越多的关注。本章将从研究背景和意义，国内外研究现状以及研究内容和创新点
三个方面进行论述。

\section{研究背景和意义}
语音通常是指人类发出的包含有语义信息的声音。因此一段语音中所包含的信息可以分为语义信息和非语义信息\cite{kinnunen2010overview, 刘蕊2009发声的生理结构和嗓音的保护}。
即使有少部分说话人信息存在于语义信息中，如方言，说话风格等，在语音转换中，非语义信息仍和说话人信息有较强的相关性\cite{Nurminen12}。
所以当前在语音转换上的研究和实现主要以语音中的非语义信息为转换对象，而其中的语义信息则在转换过程中尽可能完整保留。
广义的语音转换可分为非特定人语音转换和特定人语音转换两大类，非特定人的语音转换是指通过处理将原始说话人的语音转换为
不像原始说话人的声音，例如老人、小孩、男性、女性等。而在实际应用中，语音转换通常是将原始说话人的语音转换成特定目标
说话人的语音，建模难度要高于非特定人语音转换。

根据构造语音转换模型时的数据条件的不同，语音转换可以分为平行语料的
语音转换和非平行语料的语音转换。平行语料的语音转换是指原始说话人和目标说话人的训练数据具有相同的文本内容，因此可以
做到从原始音频到目标音频的一一对应，实现有监督训练。而非平行语料则假设训练数据没有重叠的文本内容，对于原始说话人的
每一段语音，没有可以作为标签的目标说话人语音，是无监督训练。由于在实际应用中，平行语料的训练数据获取难度大，成本高，
而非平行的语料在现实生活中相对较容易收集，非平行语料的语音转换在近两年受到越来越多研究人员的关注，也在深度学习的
浪潮下，得到了飞速发展。非平行语料可以进而拆分为语种内非平行语料和
跨语种语料。在跨语种的语音转换中，原始说话人和目标说话人不仅在说话人信息上有差别，在整体的语义信息上也有着较大的差别，
这对转换模型的建模能力提出了更高的要求，目前跨语种语音转换的研究还处于初步阶段。

语音转换作为在近两年发展较快的研究方向，目前还少有非常成熟的商用系统，但其在很多领域都有非常广泛的应用前景，例如：
\begin{itemize}
    \item \textbf{个性化语音合成:}语音转化可以帮助实现个性化语音合成。语音合成 (Text-to-Speech, TTS) 是指通过输入说话人无关的文本，来得到某个
    特定说话人的对应语音。对于当前语音合成技术的发展，通常使用特定说话人十几到几十个小时的经过标注的训练数据就可以合成自然度
    和相似度很高的语音。但大量的训练数据和人工标注工作，使得构建语音合成模型的成本极高，这对于普通人而言是极难
    实现的。对于这类问题，通常有两种解决思路，第一种是对语音合成模型进行调整来使得其可以合成另一个人的声音，常见
    的做法包括构建多说话人的语音合成模型\cite{gibiansky2017deep,ping2017deep,fan2015multi}
    以及说话人自适应方法\cite{tamura2001adaptation,wu2015study,yamagishi2009analysis}。该方法可以
    通过较少的数据实现个性化语音合成，但依旧无法避免标注成本，且训练语音合成模型也需要较长的时间。另一种方法则是
    利用语音转换技术\cite{kain1998spectral,arslan1999speaker}。语音转换技术通常只需要说话人很少的数据（几十分钟至几小时）就可以得到一个效果不错的语音转换
    模型，且语音转换的训练不需要文本标注，模型复杂度也小于语音合成模型。因此可以利用语音转换的优势，仅需要目标
    说话人少量的数据，将语音合成模型的说话人作为原始说话人，训练从原始说话人到目标说话人的语音转换模型，便可以使用语音合成模型生成原始说话人的
    声学特征序列，再通过语音转换模型得到目标说话人的声学特征序列。
    \item \textbf{发音援助：}语音转换可以帮助发音障碍人群更好的交流，提高语音的可懂度。每1000个新生儿中就有
    2-3个患有大脑性瘫痪，其中有10\%-15\%属于痉挛性脑瘫。这种脑瘫会限制肢体动作的正常表现，而与发音相关的
    肢体运动则会导致发音不稳定，不清晰\cite{hollegaard2013joint,aihara2013individuality}。
    受到发音障碍困扰的痉挛性脑瘫患者通常只能通过语气词和写字交流。由于发音障碍主要来自于辅音部分，因此则可以通过
    语音转换技术将原始的辅音部分转换为正常说话人的声学特征，元音保持不变，这样则可以很大程度提升障碍语音的清晰度。
    \item \textbf{语音翻译：}语音转换可以实现更完备的语音翻译。在深度学习的帮助下，机器翻译技术也得到了迅速的
    发展。在实现高质量，高准确率的翻译下，机器翻译也逐渐扩展到更多的语种，同时为了能够实现更便捷的交流，语音翻译
    也成为了机器翻译的重要应用方向。一个语音翻译系统通常需要语音识别，机器翻译，语音合成三个技术的支持。
    直观上，语音翻译系统生成的声音，应与输入语音的说话人保持一致，然而对于语音合成系统，要实现这样的功能，则面临
    训练数据量和跨语种两个挑战。原始说话人的训练数据量通常很少，即使有较多的数据，目前在跨语种的语音合成依旧没有
    较好的解决方案。因此可以使用跨语种语音转换技术将语音合成的第三方说话人转换为输入语音的说话人，实现真正的只翻译语义，
    保留说话人信息不变的语音翻译系统\cite{desai2010spectral}。
    \item \textbf{声纹识别：}语音转换可以提升声纹识别系统的鲁棒性。除了传统的指纹加密、字符加密等外,利用语音
    来识别身份作为加密的方式也引起了人们的兴趣,因而说话人识别和验证也越来越受到重视。出于实际应用的考虑，错误地将无关说话人
    识别为目标说话人是难以接受的，因而说话人验证系统很容易收到各种各样的攻击，比较典型的包括重放攻击 (replay attack) 
    和语音转换攻击。其中语音转换攻击通过将无关说话人的语音转换为目标说话人的语音来欺骗声纹识别系统，
    转换出来的语音也可以作为声纹识别的负例样本来减少声纹识别的误判率\cite{kinnunen2012vulnerability}。
    同理，声纹识别也可以对语音转换的相似程度做出判定。声纹识别和语音转换可以看做互为对抗任务，语音转换尽可能转换
    更接近目标说话人的语音，而声纹识别则需要尽可能地识别出最先进的语音转换系统转换出来的语音。

\end{itemize}

\section{国内外研究现状}
语音转换始于二十世纪80年代，在三十多年各国研究人员的不断努力下，语音转换模型和方法在不断的进步和完善。随着近几年
深度学习的发展，语音转换技术经历了一次爆发，基于神经网络的方法被不断提出。为了使世界各地的研究者可以相互比较各自的
系统，使语音转换技术可以更好的发展，2016年研究人员自发举办了第一届语音转换挑战赛 (Voice Conversion Challenge, VCC) ，
参赛团队要求在给定的数据集上开发语音转换系统，由官方对所有系统性能进行对比\cite{toda2016voice,wester2016analysis}。
在第一届VCC之后，越来越多的研究人员开始投入到语音转换的研究当中，随着技术发展的不断深入，语音转换也逐渐产生了更细的分化，
包括一对一、多对一、多对多、任意对一语音转换等，代表语音转换系统可以实现转换的原始说话人和目标说话人的数目。最初
的语音转换任务主要专注于平行语料的语音转换，即原始说话人和目标说话人的训练数据具有相同的文本内容。然而在技术落地
时，研究人员逐渐发现在实际的应用场景中，获取平行语料的成本非常高，而且平行语料之间差别过大也会严重影响特征对齐效果，从而
降低语音转换的性能。因此，语音转换的研究重心逐渐由平行语料向非平行语料倾斜。在2018年的第二届语音转换挑战赛上，
非平行语料的语音转换被添加到挑战项目中\cite{lorenzo2018voice}。

如前文所述，语音转换需要尽可能保留原始语音中的语义信息，通过对其中的非语义信息进行变换来改变说话人身份。一个完整的语音转换
系统包括训练模块和转换模块两部分。训练模块包括训练数据特征提取和预处理，特征对齐和转换模型训练三个步骤。转换模块包括
输入数据特征提取和预处理，声码器合成和特征转换这三个部分。因此，声学特征对齐的准确度、转换模型的转换性能和声码器的合成
性能是决定语音转换音质和相似度的三大因素。

特征对齐主要应用于平行语料的语音转换任务中。相同语义信息的原始和目标音频长度往往是不一致的，就会导致不同长度的特征序列
在学习映射函数时无法做到帧级别的一一对应。为了更精准的对齐，常使用动态时间规整算法 (Dynamic Time Warping, DTW) 计算两个
特征序列之间的对齐路径，所得到的对齐路径再通过复制或插值的方式将两个序列对齐到同一长度。对于非平行语料的语音转换，会根据不同的模型
使用不同的对齐方式，如无监督聚类法\cite{sundermann2003vtln}，监督迭代法\cite{erro2009inca}和音素对齐法\cite{ye2004voice}。

声码器是语音信号的分析合成系统，通过对语音信号进行分析，提取出不同的声学特征，同时也可以通过声学特征重建波形。
传统的声码器以数字信号处理算法为基础，将输入的语音信号通过傅里叶变换分析成具有不同意义的特征，如基频、频谱、非周期信号、倒谱等。
常用的数字信号声码器包括STRAIGHT\cite{kawahara1997speech}、tandemSTRAIGHT\cite{kawahara2008tandem}、WORLD\cite{morise2016world}等。
近年来，基于深度学习的声码器在生成语音的自然度上已经能够接近真实音频，使得语音生成相关的任务在自然度和相似度上整体得到了提升。
神经网络声码器通过大量语音数据建模声学特征和音频样本点之间的关系，除了合成音质显著好于传统声码器之外，神经网络声码器的
输入特征可以根据具体任务进行修改和优化，甚至可以实现文字转语音的任务。常用的神经网络声码器包括
WaveNet\cite{oord2016wavenet,tamamori2017speaker,oord2017parallel}、WaveRNN\cite{kalchbrenner2018efficient}、LPCNet\cite{valin2019lpcnet}等。
声码器的性能判断主要包括重构语音的音质，鲁棒性和生成实时率。

特征转换是语音转换中的核心和关键，转换模型的好坏会直接影响语音转换系统的性能。如前文所述，特征转换需要在转换过程中保持语义信息不变，
只修改特征中的说话人相关特征，由于并没有显式的说话人特征存在，因此如何只修改特征中的说话人信息而保持其他信息不变则
是特征转换部分的主要挑战。研究人员提出了很多不同的方法来解决这个问题。

平行语料的转换方法主要可以分为四大类：基于实例化的转换、基于规则的转换、基于概率统计的转换和基于神经网络的转换。
基于实例化的方法主要有单元选择法 (Unit Selection)\cite{shuang2008voice,sundermann2006text,wu2013exemplar} 
和基于非负矩阵分解法 (Non-negative Matrix Factorization, NMF)\cite{takashima2012exemplar,wu2014exemplar,zhang2015regularized} 。
基于规则的方法则是频率弯折法 (Frequency Warping, FW)\cite{shuang2008voice,erro2009voice,tian2015sparse,Toda2001Voice} 。
基于概率统计的方法主要是指高斯混合模型法 (Gaussian Mixture Model, GMM)\cite{chen2003voice,kain1998spectral,kobayashi2016nu,stylianou1998continuous} 。
基于神经网络的方法在近两年发展迅速，许多不同的模型都被提出可以实现语音转换的任务，包括人工神经网络 (Artificial Neural Networks, ANN)\cite{desai2010spectral} 、
深度神经网络 (Deep Neural Networks, DNN)\cite{aryal2015articulatory,chen2014voice} 、
循环神经网络 (Recurrent Neural Networks, RNN)\cite{nakashika2015voice,sun2015voice} 、
卷积神经网络 (Convolution Neural Networks, CNN)\cite{kaneko2017sequence}，生成对抗网络(Generative Adversarial Network, GAN)\cite{hsu2017voice,kaneko2017sequence} 、
序列到序列 (Sequence-to-Sequence)\cite{kameoka2018convs2s,tanaka2019atts2s,zhang2019improving} 
和基于WaveNet的方法\cite{polyak2019attention}。

非平行语料的转换方法可以分为三大类：基于音素后验概率图 (Phone PosteriorGram, PPG) 的方法、基于对抗学习 (Adversarial Learning) 的方法和基于变分自编码器 (Variational AutoEncoder, VAE) 的方法。
基于音素后验概率图的方法主要是通过语音识别模型从目标说话人的声学特征中提取说话人无关的语义信息，然后再直接
学习从语义信息到目标说话人的声学特征的映射关系\cite{sun2016phonetic}。语义信息的表示即声学建模单元的后验概率，可以根据不同任务选择
不同的建模单元，也可以根据不同的声码器进行不同的优化\cite{liu2018hccl,lu2019compact,liu2019jointly,zhou2019cross}。
基于对抗学习的方法主要受对偶学习的思想启发，通过同时学习若干个对偶任务来达到无监督学习的目的。包括一对一转换
CycleGAN\cite{kaneko2017parallel,kaneko2019cyclegan}和多对多转换StarGAN\cite{kameoka2018stargan,kaneko2019stargan}。
基于变分自编码器的方法通过在变分自编码器的中间变量中加入说话人表示，来实现无监督的说话人风格转换\cite{hsu2016voice,kameoka2019acvae}。
变分自编码器和对抗学习相结合\cite{hsu2017voice}，变分自编码器和音素后验概率图相结合\cite{saito2018non}的方法也被提出。

% 跨语种的方法，可以单独写，也可以包括在非平行中
% 尽管跨语种语音转换的研究还处于初步阶段，但研究人员针对跨语种的特点，提出了一些有效的方法。包括：
% 

对于转换的声学特征，常用的方法是使用声码器分析出梅尔倒谱，基频，非周期信号三个特征，这三个特征分别做不同的处理：
梅尔倒谱使用转换模型进行转换，基频使用均值方差线性缩放的方式进行转换，非周期信号保持不变。三个特征分别处理后再使用
声码器合成为波形。近年随着神经网络声码器的发展，直接使用频谱建模也可以得到较为不错的转换语音。



虽然语音转换技术越来越成熟，方法也越来越多样化，但是当前技术仍旧存在较多挑战：
\begin{itemize}
    \item DTW的对齐方式准确度较差，尤其是当需要对齐的两句话差别较大时，对齐往往有较大的误差，这对转换模型的学习有直接的影响。
    \item 尽管当前非平行语料的语音转换方法可以实现较好的语音转换，但转换语音整体的自然度和相似度依旧有较高的提升空间。
    如何在有限的数据条件下尽可能提升转换模型的建模能力是当前主要的研究方向。
    \item 由于转换特征和真实特征之间的分布差异，导致声码器在转换特征上合成的声音音质较差。该问题一方面需要从声码器的鲁棒性角度入手，
    尽可能提升声码器对带噪声声学特征的适应能力，另一方面则是通过改进转换模型来缩小转换特征和真实特征之间的距离。
    \item 传统的线性变换对基频而言是较为简单和直接的，但实际上音调的变化往往是更为复杂的，需要更多非线性变换来进行更为准确的基频转换。
\end{itemize}

\section{研究内容和创新点}
本文在CycleGAN模型的基础上，对非平行语料和跨语种语料下的语音转换任务分别提出了不同的训练模型和框架。

\begin{itemize}
    \item 对于标准的非平行语音转换，原始和目标语料属于同一语种。本文首次将CycleGAN模型与基于梅尔频谱的WaveNet声码器结合，
    并使用包含基频信息的梅尔频谱特征作为声学特征，该方法不仅能提升转换语音的上限，还可以实现基频的隐式转换。
    通过分析标准CycleGAN模型的训练和更新方式，提出半优化CycleGAN模型，
    该模型优化标准模型训练中的部分更新过程，可以在不改变模型结构的条件下，提升转换语音的自然度和相似度。
    针对转换时出现的发音错误问题，同时提出使用基频辅助特征帮助生成器和判别器更好地实现基频转换。
    \item 对于跨语种语音转换，原始和目标语料属于不同语种。对于这类原始和目标领域相差较大的情况，
    判别器在训练时很容易更偏向于区分领域差异，而不是说话人差异，从而导致转换效果较差，甚至无法有效转换。
    针对该问题，本文参考说话人识别中的说话人特征d-vector，来使用说话人特征提取器过滤掉声学特征中的领域差异。
    使用不同说话人数据预训练说话人分类器，并将训练结束的说话人分类器去掉输出层得到说话人特征提取器，
    该提取器可作为CycleGAN中判别器的前置网络，并保持参数固定。
    说话人特征的引入减小了正负例之间的领域差异，使得判别器可以直接对说话人特征进行判断，有效地提升了转换性能。
\end{itemize}


\section{章节安排}
本文章节内容安排如下：

第一章　绪论：首先简要介绍了语音转换的研究背景，以及当前存在的应用场景；接着介绍了语音转换的发展历史，
和语音转换中的几个重要部分：特征对齐、声码器、特征转换和特征提取，及其当前的研究进展。最后简要描述了
本文的主要研究工作和贡献。

第二章　语音转换系统：介绍了语音转换系统各个部分的技术细节，总结和对比了在语音分析与合成，特征对齐，特征转换
和韵律转换上的传统和前沿做法。

第三章　非平行语料的语音转换：对非平行语料的语音转换任务进行详细描述。介绍和对比了当前常见的特征转换方法，并
详细介绍了基于CycleGAN的语音转换方法，这也是本文所采用的方法。

第四章　基于半优化CycleGAN的非平行语料语音转换：本章详细阐述了本文提出的基于半优化CycleGAN的非平行语料语音转换方法。
包括采用基于梅尔频谱的WaveNet模型作为声码器，半优化CycleGAN模型以及基频辅助特征。最后介绍实验配置并对主观实验和客观实验
结果进行描述和分析。

第五章　基于说话人特征的跨语种语音转换优化方法：本章详细阐述了本文设计的基于说话人特征的跨语种语音转换方法。首先介绍了
跨语种语音转换及其难点；接着介绍了说话人识别和说话人特征d-vector的相关概念；然后详细描述了引入说话人特征的跨语种语音转换方法；最后对
主观实验和客观实验的实验进行配置介绍和结果分析。

